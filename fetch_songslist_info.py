#! /usr/bin/env python3
# -*- coding: utf8 -*-
# (c) Author: <kisfg@hotmail.com in 2024,2025>
# SPDX-LICENSE-IDENTIFIER: GPL2.0-ONLY
# Last modified at 2025/10/04 ÊòüÊúüÂÖ≠ 20:46:44
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU Library General Public
# License as published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
# Library General Public License for more details.
#
# You should have received a copy of the GNU Library General Public
# License along with this library; if not, see <https://www.gnu.org/licenses/>.
"""
Êú¨Á®ãÂ∫èÂè™Áî®‰∫é‰∏™‰∫∫Áà¨ÂèñÁΩëÊòì‰∫ëÊ≠åÂçïÁöÑÊ≠åÊõ≤ÂêçÁ≠â‰ø°ÊÅØ‰ª•Áî®‰∫éÁïôÂ≠òÂ§á‰ªΩ„ÄÇ
‰ΩøÁî®ÊñπÂºèÔºö
	ÈÄöËøáÊµèËßàÂô®Êèê‰æõËá™Ë∫´ÁôªÂΩïÂêéÂæóÂà∞ÁöÑ cookie„ÄÅÊ≠åÂçï idÔºåÁÑ∂ÂêéËøêË°åËé∑Âèñ„ÄÇ

‰ºö‰∏¥Êó∂ÁîüÊàêÂØπÂ∫îËåÉÂõ¥ÁöÑ‰∏¥Êó∂Êñá‰ª∂‰æõÂ§öÁ∫øÁ®ã‰∏¥Êó∂ÂÜôÂÖ•„ÄÇ

ÂëΩ‰ª§Ë°å‰º†ÂèÇÂøÖË¶ÅÁöÑÂèÇÊï∞Ôºö
	- login_dummy: ÂÇÄÂÑ°Ë¥¶Âè∑„ÄÇÂÖ∂‰∏≠ token Âíå cookie ÂøÖË¶Å„ÄÇ
	- songslist_author: ÁõÆÊ†áÊ≠åÂçï„ÄÇlist-id ÂøÖË¶ÅÔºå
						‰∏îÁõÆÂâç $(sys.platform)-backup-dir ‰πüÂøÖË¶Å„ÄÇ

ÊúâÂÖ≥ËÆøÈóÆÊï∞ÊçÆÂ∫ì„ÄÅÁªÑÁªáÂª∫Ë°®ÁöÑÈÄªËæë‰ªçÂú®ÊñΩÂ∑•‰∏≠üößÔºå‰ªç‰∏çËÉΩ‰øùËØÅÂâçÂêéÂêëÂÖºÂÆπ
ÈÖçÁΩÆÂ•Ω‰ª•ÂêéËá≥Â∞ë‰øùËØÅËÉΩË∑ë„ÄÇ
"""

import sys
import random
import threading
from queue import Queue
from typing import Optional
from io import TextIOWrapper
from functools import partial
from multiprocessing import cpu_count
from concurrent.futures import ThreadPoolExecutor

from rich.progress import Progress, TaskID

from misc_utils.file_operator import (
	write_in_given_mode,
	append_from_ro_file,
	seek_to_remove_file,
	dir2file
)
from misc_utils.wrappers.err_wrap import seize_err_if_any
from misc_utils.http_meths.man import getter, poster
from misc_utils.opts.json.conf_reader import (
	PRIVATE_CONFIG,
	load_json_from_str,
	deserialize_json_or_die
)
from misc_utils.logger import DEBUG_LOGGER
from misc_utils.header import HEADER
from misc_utils.ref_types import (
	SongsResp,
	SongDetails,
	PlaylistDetail,
	PlaylistTrackInfo
)
from misc_utils.time_aux import (
	unix_time,
	unix_ts_to_time,
	US_TIME_FORMAT, 
	unix_ms
)
from misc_utils.args_loader import PARSER
from misc_utils.str_aux import dic2json_str
from misc_utils.opts.db.sqlite import DBfd
from misc_utils.diff_calc import myers_diff_comparer, DiffOp
from crypto_aux.manual_deobfus import netease_encryptor

# TODO: Â¶ÇÊûúÁ∫øÁ®ãÊâßË°åËøáÁ®ã‰∏≠ÈÅáÂà∞‰ªª‰ΩïÂºÇÂ∏∏ÔºåÁõ¥Êé•ÈÄöÁü•ÂÖ∂ÂÆÉÁ∫øÁ®ãÁªìÊùüÔºåÁÆ°ÁêÜÁ∫øÁ®ãÁöÑÁà∂ËøõÁ®ãÁ≠âÂæÖÂπ∂Â¶•ÂñÑÊ£ÄÊü•ÂêéÂÜçÈÄÄÂá∫

_args = PARSER.parse_args()
del PARSER

_HTTPS: str = 'https://'
host: str = "music.163.com"
interface_prefix: str = f'{_HTTPS}interface.{host}'
# just GET
SONGSLIST_API: str = '/api/v6/playlist/detail?id='
SONG_SKIM_API: str = '/api/song/detail?ids='
# POST it
CONTENT_OF_SONG_PAPI: str = "/weapi/rep/ugc/song/get?csrf_token="
# useful urls
target_songslist_url: str = f'{interface_prefix}{SONGSLIST_API}'
target_songs_url: str = f"{interface_prefix}{SONG_SKIM_API}"
song_sniper_url: str = f'{_HTTPS}{host}{CONTENT_OF_SONG_PAPI}'
# concurrency control
_reveal_queue = Queue(maxsize=_args.threadpool_size)
_reveal_sema = threading.Semaphore(
	# ÂçïÊ†∏ CPU ËøòÊúâ‰∫∫Áî®Âêó?
	min(cpu_count(), _args.threadpool_size//2)
)
# database handle
database_fd: Optional[DBfd] = DBfd(_args.database_path)


def song_sniper(sid: int, tok: str) -> any:
	"""
	ËøîÂõû‰∏Ä‰∏™ÊØîËæÉÂ∫ûÂ§ßÁöÑÁªìÊûÑ
	"""
	global host, song_sniper_url
	origin_payload = dic2json_str({
		"songId": sid, "csrf_token": tok
	})
	assert 'Cookie' in HEADER and			\
			len(HEADER['Cookie']) != 0 and	\
			tok in HEADER['Cookie']
	changed_domains = {
		"Accept"			: "*/*",
		"Referer"			: f"{_HTTPS}{host}/reveal/song?songId={sid}&type=2",
		"Content-Type"		: "application/x-www-form-urlencoded",
		"Cookie"			: HEADER['Cookie'],
		"Host"				: host,
		"Origin"			: _HTTPS + host,
		"Priority"			: "u=1, i",
		"Sec-Fetch-Dest"	: "iframe",
		"TE"				: "trailers",
		"X-Requested-With"	: "XMLHttpRequest",
	}
	encrypted_payload, _ = netease_encryptor(origin_payload)
	ret = poster(
		url=song_sniper_url+tok,
		payload=encrypted_payload,
		alter_map=changed_domains
	)
	return ret


def _exam_hidden_sinfo(sid: int, tok: str) -> list:
	global _reveal_sema
	while True:
		_reveal_sema.acquire()
		threading.Event().wait(timeout=random.uniform(3, 6))
		# Âõ†‰∏∫Êï∞ÈáèÈóÆÈ¢òËøôÈáå‰∏çÂ§™Â•ΩÂÆåÊï¥Âú∞Êî∂ÈõÜ‰∏ãÊù•Ôºå
		# Ê≠§Â§ñÈúÄË¶ÅÊ≥®ÊÑèÂπ∂ÂèëËØ∑Ê±ÇÁöÑÈ¢ëÁéáÂíåËßÑÊ®°
		song_obj = song_sniper(sid, tok)
		if song_obj is None or len(song_obj.text) == 0:
			threading.Event().wait(timeout=random.uniform(3, 6))
			_reveal_sema.release()
			continue
		elif song_obj.status_code != 200:
			return [None, '', '', '', '', '']
		tmp = load_json_from_str(song_obj.text)
		if tmp is None or 'data' not in tmp:
			return [None, '', '', '', '', '']

		tdat = tmp['data']
		if 'playUrl' not in tdat:
			flag = None
		else:
			# TODO: ËøòÊúâÁßçÊÉÖÂÜµÊòØÊúâÔºå‰ΩÜ vip ÊâçËÉΩÂê¨
			# ‰ΩÜÊòØËøòÊ≤°‰ªéÊ∑∑Ê∑ÜjsÁúãÂá∫‰ªÄ‰πà‰∏∫‰ªÄ‰πàÂÆÉÊáÇÂæóÊó†ÁâàÊùÉÁöÑÊâÄ‰ª•ÁÑ∂Êù•ÔºåËøôÈáåÂÖàÈ∏Ω
			flag = tdat['playUrl'] is not None
		_jud = lambda x: x not in tdat or tdat[x] is None
		_muxer = lambda x: [] if _jud(x) else tdat[x]
		_texer = lambda x: x if isinstance(x, str) else ''
		lyric = _texer(_muxer('lyricContent'))
		trans = _texer(_muxer('transLyricContent'))
		composers = ', '.join([_['artistName'] for _ in _muxer('composeArtists')])
		arrangers = ', '.join([_['artistName'] for _ in _muxer('arrangeArtists')])
		lyricists = ', '.join([_['artistName'] for _ in _muxer('lyricArtists')])
		return [flag, lyric, trans, composers, arrangers, lyricists]


@seize_err_if_any()
def process_song_info_in_chunk(
	integrated_conf: dict,
	songs_detail: list[SongDetails],
	play_list: list[PlaylistTrackInfo]
) -> None:
	global _reveal_sema, _reveal_queue, database_fd

	st_pos = integrated_conf['st_pos']
	soid = integrated_conf['soid']
	bar_id = integrated_conf['taskID']
	for idx, a_song in enumerate(songs_detail):
		
		duration = a_song['duration']
		mins, ms = duration // 60_000, duration % 1_000
		sec = (duration - mins * 60_000 - ms) % 1_000
		final_dura = f'{mins}:{sec:02d}.{ms:03d}'
		del mins, sec, ms, duration

		song_id = a_song['id']
		# TODO: Â¶ÇÊûúÊï∞ÊçÆÂ∫ìÈáåËÉΩÊâæËÄå‰∏î‰ø°ÊÅØÈÉΩÊòØÂÖ®ÁöÑÔºåÂ∞±Ê≤°ÂøÖË¶ÅÂéªÂÜçÊ¨°ËØ∑Ê±ÇÔºåÊÉ≥ÂäûÊ≥ï‰øùËØÅËøô‰∏ÄÁÇπÂπ∂Áªô‰∏™‰ºòÂåñ
		attacher = _exam_hidden_sinfo(song_id, integrated_conf['token'])
		copyleft = attacher[0]
		_lyc, _trl = attacher[1], attacher[2]
		arrangers, composers = attacher[3], attacher[4]
		lyricists = attacher[5]
		del attacher
		_reveal_sema.release()

		# ‰∏Ä‰∫õÂÜÖÂÆπÂèØ‰ª•Áõ¥Êé•‰º†ÁªôÊï∞ÊçÆÂ∫ìÊù•ÂÅö
		album_publish_time: int = a_song['album']['publishTime']
		database_fd.insert_if_not_exist_else_renew(
			'albums', {'album_id': a_song['album']['id'] }, { 
				"company": a_song['album']['company'],
				'name': a_song['album']['name'],
				"publish_time": unix_ts_to_time(album_publish_time/1000)
			}
		)
		# Êúâ‰∫õÊ≠åÁöÑÊ≠åËØçÂíåÁøªËØëÂèØËÉΩÂú®ÂêéÈù¢‰ºöÂä†ÂÖ•ËøõÊù•
		# ÊúÄÂ•ΩËøòÊòØÂÖàÊèíÂÖ•ÁÑ∂ÂêéÂÜçÊõ¥Êñ∞Ëøô‰∏§‰∏™Âüü
		database_fd.update_item_in_tbl(
			"songs", { "song_id": song_id }, {
				'tr_pos': a_song['position'], 
				'album_id': a_song['album']['id'],
				"name": a_song['name'],
				'duration': final_dura,
				"lyrics": _lyc.replace('\n', '\\n'),
				"translatext": _trl.replace('\n', '\\n'),
				"vocals": ', '.join([v['name'] for v in a_song['artists']]), 
				"arrangers": arrangers, "lyricists": lyricists, 
				"composers": composers, "fetchable": copyleft, 
				"subtitle": ', '.join(a_song["alias"])
		})
		by_whom = play_list[idx]['uid']
		status, _ = database_fd.is_item_in_tbl(
			('user_id',), (by_whom,), 'users'
		)
		if not status:
			database_fd.insert_to_tbl(
				'users', { 'user_id': by_whom }
			)
		_tmp_ubid = database_fd.insert_if_not_exist_else_renew(
			'users_behaviors', { 'soid': soid, 'user_id': by_whom }
		)
		if _tmp_ubid is not None:
			ubid = _tmp_ubid
		else:
			status, row = database_fd.is_item_in_tbl(
				('soid', 'user_id'), (soid, by_whom),
				'users_behaviors'
			)
			# Ê≤°ÊúâÂá∫Áé∞ËøáÁöÑÈ°πÁõÆÔºåËøô‰∏™Êó∂ÂÄôÊâçÂ∫îËØ•Ë¶ÅÊèíÂÖ•
			ubid = row["ubid"] \
				if status else database_fd.insert_if_not_exist_else_renew(
				'users_behaviors', { 'soid': soid, 'user_id': by_whom }
			)
			del status, row
		database_fd.update_item_in_tbl(
			'songs_status_in_songslists',
			{ 'song_id': song_id, 'ubid': ubid },
			{ "op_time": unix_ts_to_time(play_list[idx]['at']/1_000, US_TIME_FORMAT) }
		)
		_reveal_queue.put((bar_id, 0.6))


@seize_err_if_any()
def query_song_detail_in_range(
	bar_id: TaskID,
	integrated_conf: dict,
	l: int, r: int,
	play_list: list[PlaylistTrackInfo]
) -> None:
	"""
	{
		"res-song-get": {
			type: "GET",
			url: "/api/song/detail",
			format: function(m1x, e1x) {
				if (!!m1x.songs && m1x.songs.length > 0)
					m1x.song = m1x.songs[0];
				else
					m1x.song = bqK0x;
				delete m1x.songs;
				return xr5w(m1x, e1x)
			},
			filter: function(e1x) {
				e1x.data.ids = "[" + e1x.data.id + "]"
			}
		}
	}
	:return: None
	"""
	global target_songs_url, _reveal_sema, _reveal_queue
	# ÈöèÊú∫Á≠â 1 ÔΩû 10 Áßí
	threading.Event().wait(timeout=random.randint(1, 10))
	res = getter(
		url=f'{target_songs_url}{[_s["id"] for _s in play_list]}',
		err_info=f'Catch an Exception in range [{l}, {r}): '
	)
	_check = lambda x: x is None or len(x.text) == 0 or x.status_code != 200
	songs_detail: Optional[SongsResp] = \
			None if _check(res) else	\
			load_json_from_str(res.text)
	del res

	nxt_merger = {
		'token': integrated_conf['token'],
		'taskID': bar_id,
		'st_pos': l,
		'soid': integrated_conf['soid'],
	}
	process_song_info_in_chunk(nxt_merger, songs_detail['songs'], play_list)
	_reveal_queue.put((bar_id, 0.4*(r-l)))
	return


def check_progress_state(prog_man: Progress) -> None:
	"""
	ÁªàÁ´ØËøõÂ∫¶Êù°ÊòæÁ§∫ÂáΩÊï∞
	"""
	global _reveal_queue
	while not prog_man.finished:
		req: tuple[TaskID, int] = _reveal_queue.get()
		prog_man.update(req[0], advance=req[1])


@seize_err_if_any()
def songs_tasks_distributor(
	integrated_conf: dict,
	task_list: list[PlaylistTrackInfo],
	fn=query_song_detail_in_range
) -> None:
	"""
	ËøîÂõûÂπ∂ÂèëÊâßË°åÂâçÔºåËÆ°ÁÆóÂæóÂà∞ÁöÑ‰ªªÂä°ÂàóË°®„ÄÇ
	"""
	global _reveal_queue
	workers = integrated_conf['worker_num']
	split_size = integrated_conf['split_size']

	lena = len(task_list)
	other, reminder = lena // split_size, lena % split_size
	tasks_queue = [(_*split_size, (_+1)*split_size) for _ in range(0, other)]
	tasks_queue.append((other*split_size, (other*split_size)+reminder))

	# Áº©ËøõÂ§ö‰∫ÜÂ∞±Êàê‰∫ÜÊ®™Ë∫∫ÁùÄÁöÑshxt
	with Progress() as progress_man:
		_prog_rec = []
		for _ in range(len(tasks_queue)):
			tup = tasks_queue[_]
			_tmp = progress_man.add_task(
				# ËøôËæàÂ≠êÊääÂçÅ‰∏áÈ¶ñÊ≠åÊï¥ÁêÜÂà∞‰∏Ä‰∏™Â∏∏Âê¨ÁöÑÊ≠åÂçïÈáåÂæàÈöæ
				# ÁâπÂà´ÊòØÂÆöÊúüÁöÑËßÇÊµã‰ºöËÆ©ËøôÁßçÊï∞ÈáèÁ∫ßÁöÑÊï∞ÊçÆÁàÜÁÇ∏ÂºèÂ¢ûÈïø
				f"Range:[{tup[0]:>4d},{tup[1]:>4d})",
				total=tup[1]-tup[0]
			)
			_prog_rec.append(_tmp)
		# Áî±‰∫éÂä†‰∫ÜËøõÂ∫¶Êù°ÔºåÁ∫øÁ®ãÊ±†ÈúÄË¶ÅÂ§öÊâ©‰∏Ä‰∏™ÁªôËøõÂ∫¶Êù°Á∫øÁ®ã
		nxt_merger = {
			'token': integrated_conf['token'],
			'soid': integrated_conf['soid'],
		}
		with ThreadPoolExecutor(max_workers=workers+1) as per_mission:
			per_mission.submit(check_progress_state, progress_man)
			for i, choice in enumerate(tasks_queue):
				per_mission.submit(
					fn, # Ë¶ÅË∞ÉÁî®ÁöÑÂáΩÊï∞
					_prog_rec[i], nxt_merger,
					choice[0], choice[1],
					task_list[choice[0]:choice[1]]
				)
			del task_list


@seize_err_if_any()
def songslist_info_gen(
	tok: str,
	workersnum: int,
	crawl_conf: dict,
	split_size: int=100
) -> None:
	"""
	ÂàÜÊûêÔºöcore_52f85c5f5153a7880e60155739395661.js^[1]‰∏ã
	Á¨¨ 69 Ë°åÂåøÂêçÂáΩÊï∞ (function()) ÈáåÊúâ

	{
		"res-playlist-get": {
			type: "GET",
			url: "/api/v6/playlist/detail",
			format: function(m1x, e1x) {
				var res = j1x.bsN0x(m1x);
				res.playlist = res.result;
				delete res.result;
				return xr5w(res, e1x)
			}
		}
	}

	Âè™ÈúÄ‰º† id ÂàóË°®Â∞±ÂèØ‰ª•Ëé∑ÂèñÂà∞ÂàóË°®ÂÜÖÁöÑÊâÄÊúâÊ≠åÊõ≤„ÄÇ
	ÂàóË°®ÈïøÂ∫¶‰∏çËÉΩÂÆöÂæóÂ§™Â§ßÔºåÂê¶ÂàôÂêéÊûúËá™Ë¥ü

	- [1]: 2025/02/08: core_70d0eefb570184a2b62021346460be95.jsÔºå
	       ÂèçÊ≠£ÁêÜËß£‰∏∫ core.js„ÄÇ
	"""
	global interface_prefix, target_songslist_url, database_fd

	response =getter(
		url=f"{target_songslist_url}{crawl_conf['list-id']}",
		err_info='fatal error while fetching songslist: '
	)

	if response is None:
		DEBUG_LOGGER.error('unable to fetch any songslist info')
		return
	elif response.status_code != 200:
		DEBUG_LOGGER.error(response.status_code, response.text)
		exit(1)

	serializer = response.text
	tmp: PlaylistDetail = deserialize_json_or_die(serializer, 'playlist')
	curr_time = unix_ms()
	del serializer, response

	songslist_updatetime = unix_ts_to_time(tmp["updateTime"]/1_000)
	songslist_birthday = unix_ts_to_time(tmp["createTime"]/1_000)
	slid = tmp["id"] # songslist_id
	track_cnt, share_cnt = tmp["trackCount"], tmp["shareCount"]
	likers_num, ref_hits = tmp["subscribedCount"], tmp["playCount"]
	description = tmp["description"]
	songslist_title = tmp["name"]

	creator_info = tmp["creator"]
	creator_id = creator_info["userId"]
	creator_name = creator_info["nickname"]
	creator_brief = creator_info['signature'].replace('\n', '\\n')
	del creator_info
	playlist = tmp['trackIds']
	del tmp
	print(f'For songslist-id {slid}')
	st_time = unix_time()
	# DB insert operations
	database_fd.insert_if_not_exist_else_renew(
		'users',
		{ 'user_id': creator_id },
		{ 'name': creator_name, 'brief': creator_brief }
	)
	database_fd.insert_if_not_exist_else_renew(
		'songslists',
		{ 'songslist_id': slid, 'user_id': creator_id },
		{ 'birthday': songslist_birthday }
	)
	soid = database_fd.insert_to_tbl(
		'songslists_observation', {
		'songslist_id': slid, 'user_id': creator_id, 
		'observation_time': unix_ts_to_time(curr_time/1000)
	})
	assert soid is not None
	def _songslist_attr_tbl_init(name: str, val: int | str) -> None:
		database_fd.insert_if_not_exist_else_renew(name+'_rec', { 'soid': soid }, { name: val })
	_songslist_attr_tbl_init('ref_hits', ref_hits)
	_songslist_attr_tbl_init('likers', likers_num)
	_songslist_attr_tbl_init('share_cnt', share_cnt)
	_songslist_attr_tbl_init('description', description)
	_songslist_attr_tbl_init('titles', songslist_title)
	ubid = database_fd.query_items_in_tbl(
		'users_behaviors',
		{ 'soid': soid, 'user_id': creator_id },
		'ubid', True
	)
	if ubid is None or len(ubid) == 0:
		ubid = database_fd.insert_to_tbl(
			'users_behaviors', 
			{ 'soid': soid, 'user_id': creator_id }
		)
	curr_idxs = [_["id"] for _ in playlist]
	sql_records = database_fd.query_items_in_tbl(
		"curr_songslists",
		{ "songslist_id": slid },
		'pos_val'
	)
	songslist_ids = [_["song_id"] for _ in sql_records] if sql_records is not None else []
	# ÂÖàÊü•ÊòØÂê¶Â∑≤ÊúâÊ≠åÂçïÁöÑÁª¥Êä§ËÆ∞ÂΩï
	# Â¶ÇÊûúÊúâÁõ¥Êé•ÊãøÊù•ÂÉègit diff‰∏ÄÊ†∑ÊØîËæÉÂ∑ÆÂºÇ
	# ÈúÄË¶ÅÁúãÁöÑÊòØ‰∏ä‰∏ÄÊ¨°ÁöÑÂÜÖÂÆπÔºü
	# ‰ΩÜÊòØ‰∏ä‰∏ÄÊ¨°ÂÜÖÂÆπÊòØÂ∑ÆÂºÇÔºåÂ¶ÇÊûúË¶ÅÁúãÔºåÊØèÊ¨°Â∞±ÈÉΩÈúÄË¶ÅÂú®ËøôÈáåÁÆóÁ¨¨‰∏ÄÊ¨°ÁúãÁßØÁ¥ØÂà∞Áé∞Âú®ÁöÑÂ∑ÆÂºÇ
	# ‰∏çÂ¶®Â∞ÜËøô‰∏™ÂÜÖÂÆπÂçïÁã¨ËÆ∞ÂΩï‰∏∫‰ΩçÁΩÆ‰ø°ÊÅØË°®
	# ÊØèÊ¨°Âè™ÈúÄË¶ÅËÅîÂêàÊü•ËØ¢ÔºåËøôÊ†∑Â∞±‰∏çÁî®ÊäòËÖæÊù•ÊäòËÖæÂéª‰∫ÜÔºå‰∏çÂçïÁã¨ËÆ∞ÂΩï
	len_ret = len(sql_records) if sql_records is not None else -1
	del sql_records, creator_id, creator_name, creator_brief
	del description, songslist_title, share_cnt, likers_num, ref_hits
	differs = myers_diff_comparer(songslist_ids, curr_idxs)
	songslist_ids = []
	for idx, edit_item in enumerate(differs):
		if edit_item[0] == DiffOp.keep:
			songslist_ids.append(edit_item[1][0])
			continue
		database_fd.insert_if_not_exist_else_renew('songs', { 'song_id': edit_item[1][0] })
		database_fd.insert_if_not_exist_else_renew(
			'songs_status_in_songslists', {
				'song_id': edit_item[1][0], 
				'ubid': ubid
			}, { f'{str(edit_item[0]).split(".")[-1]}_pos': edit_item[1][1]+1 }
		)
		if edit_item[0] == DiffOp.delete:
			continue
		songslist_ids.append(edit_item[1][0])
	del differs, curr_idxs
	for idx, item in enumerate(songslist_ids):
		if idx < len_ret:
			database_fd.update_item_in_tbl(
				"curr_songslists",
				{ "pos_val": idx+1, "songslist_id": slid }, 
				{ 'song_id': item }
			)
		else:
			database_fd.insert_to_tbl(
				'curr_songslists', 
				{ 'pos_val': idx+1, "songslist_id": slid, 'song_id': item }
			)
	for idx in range(len(songslist_ids), len_ret):
		database_fd.remove_item_in_tbl(
			'curr_songslists',
			{ 'pos_val': idx+1, 'songslist_id': slid }
		)
	ed_time = unix_time()
	# Â∑≤ÁªèÊúâÁöÑ‰∏çÁî®ÂÜçÂéªËØ∑ÔºåÂè™ËØ∑Ê±ÇÊ≤°ÊúâÂ§á‰ªΩËøáÁöÑ
	rows = database_fd.query_null_items_in_tbl(
		'songs_status_in_songslists', 
		{ 'ubid': ubid },
		['delete_pos']
	)
	tmp = set([_['song_id'] for _ in rows ]) if rows is not None else set()
	adjust_playlist = []
	del rows, ubid, songslist_ids
	# Èô§ÈùûÊòØ‰ªÄ‰πà‰πüÊ≤°ÊúâÊâçÂÆåÂÖ®Ëé∑Âèñ
	for p in playlist:
		if p['id'] not in tmp:
			continue
		adjust_playlist.append(p)
	del playlist

	integrated_conf = {
		'token': tok,
		'split_size': split_size,
		'soid': soid,
		'worker_num': workersnum
	}

	print(f'Time-consumption-on-setup-Tables: {ed_time - st_time}s. Begin Tasks...')
	songs_tasks_distributor(integrated_conf, adjust_playlist)


if __name__ == '__main__':
	spyon: str = _args.songslist_author
	dummy: str = _args.login_dummy
	workload = _args.threadpool_size
	assert 1 <= workload  # ‰∏çËÆæ‰∏äÈôêÔºå‰ΩÜËá≥Â∞ëË¶ÅÊúâ„ÄÇ
	del _args

	dummy_conf: dict[str, str] = PRIVATE_CONFIG[dummy]
	victim_conf: dict[str, str] = PRIVATE_CONFIG[spyon]

	csrf_token, _cookie = dummy_conf["csrf_token"], dummy_conf["cookie"]
	del dummy_conf
	assert len(csrf_token) == 32 and f'__csrf={csrf_token}' in _cookie

	HEADER["Cookie"] = _cookie
	HEADER["Host"] = host
	HEADER["Referer"] = f"{_HTTPS}{host}/"
	HEADER["Connection"] = "keep-alive"
	songslist_info_gen(csrf_token, workload, victim_conf)
